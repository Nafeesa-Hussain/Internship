{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "506cb4c6",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bf55eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /Users/nafeesahussain/opt/anaconda3/lib/python3.8/site-packages (2.29.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/nafeesahussain/opt/anaconda3/lib/python3.8/site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nafeesahussain/opt/anaconda3/lib/python3.8/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/nafeesahussain/opt/anaconda3/lib/python3.8/site-packages (from requests) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nafeesahussain/opt/anaconda3/lib/python3.8/site-packages (from requests) (2023.7.22)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/nafeesahussain/opt/anaconda3/lib/python3.8/site-packages (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/nafeesahussain/opt/anaconda3/lib/python3.8/site-packages (from beautifulsoup4) (2.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests\n",
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5f520ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the product to search: guitar\n"
     ]
    },
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\".a-text-normal\"}\n  (Session info: chrome=115.0.5790.170); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n0   chromedriver                        0x00000001008766b8 chromedriver + 4937400\n1   chromedriver                        0x000000010086db73 chromedriver + 4901747\n2   chromedriver                        0x000000010042b616 chromedriver + 435734\n3   chromedriver                        0x000000010046ee0f chromedriver + 712207\n4   chromedriver                        0x000000010046f0a1 chromedriver + 712865\n5   chromedriver                        0x0000000100462ae6 chromedriver + 662246\n6   chromedriver                        0x000000010049303d chromedriver + 860221\n7   chromedriver                        0x00000001004629c1 chromedriver + 661953\n8   chromedriver                        0x00000001004931ce chromedriver + 860622\n9   chromedriver                        0x00000001004ade76 chromedriver + 970358\n10  chromedriver                        0x0000000100492de3 chromedriver + 859619\n11  chromedriver                        0x0000000100460d7f chromedriver + 654719\n12  chromedriver                        0x00000001004620de chromedriver + 659678\n13  chromedriver                        0x00000001008322ad chromedriver + 4657837\n14  chromedriver                        0x0000000100837130 chromedriver + 4677936\n15  chromedriver                        0x000000010083ddef chromedriver + 4705775\n16  chromedriver                        0x000000010083805a chromedriver + 4681818\n17  chromedriver                        0x000000010080a92c chromedriver + 4495660\n18  chromedriver                        0x0000000100855838 chromedriver + 4802616\n19  chromedriver                        0x00000001008559b7 chromedriver + 4802999\n20  chromedriver                        0x000000010086699f chromedriver + 4872607\n21  libsystem_pthread.dylib             0x00007fff206aa8fc _pthread_start + 224\n22  libsystem_pthread.dylib             0x00007fff206a6443 thread_start + 15\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     30\u001b[0m     search_term \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter the product to search: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m     products_list \u001b[38;5;241m=\u001b[39m \u001b[43msearch_amazon_product\u001b[49m\u001b[43m(\u001b[49m\u001b[43msearch_term\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResults for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msearch_term\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m index, product \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(products_list, start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n",
      "Cell \u001b[0;32mIn[4], line 20\u001b[0m, in \u001b[0;36msearch_amazon_product\u001b[0;34m(product_name)\u001b[0m\n\u001b[1;32m     18\u001b[0m product_elements \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_elements(By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv[data-asin]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m product_element \u001b[38;5;129;01min\u001b[39;00m product_elements:\n\u001b[0;32m---> 20\u001b[0m     product_title \u001b[38;5;241m=\u001b[39m \u001b[43mproduct_element\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCLASS_NAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ma-text-normal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m     21\u001b[0m     product_price \u001b[38;5;241m=\u001b[39m product_element\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspan.a-price span.a-offscreen\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m     22\u001b[0m     products\u001b[38;5;241m.\u001b[39mappend((product_title, product_price))\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/selenium/webdriver/remote/webelement.py:417\u001b[0m, in \u001b[0;36mWebElement.find_element\u001b[0;34m(self, by, value)\u001b[0m\n\u001b[1;32m    414\u001b[0m     by \u001b[38;5;241m=\u001b[39m By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR\n\u001b[1;32m    415\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 417\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIND_CHILD_ELEMENT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43musing\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/selenium/webdriver/remote/webelement.py:395\u001b[0m, in \u001b[0;36mWebElement._execute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    393\u001b[0m     params \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    394\u001b[0m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id\n\u001b[0;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py:346\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    344\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/selenium/webdriver/remote/errorhandler.py:245\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    243\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[0;32m--> 245\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[0;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\".a-text-normal\"}\n  (Session info: chrome=115.0.5790.170); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n0   chromedriver                        0x00000001008766b8 chromedriver + 4937400\n1   chromedriver                        0x000000010086db73 chromedriver + 4901747\n2   chromedriver                        0x000000010042b616 chromedriver + 435734\n3   chromedriver                        0x000000010046ee0f chromedriver + 712207\n4   chromedriver                        0x000000010046f0a1 chromedriver + 712865\n5   chromedriver                        0x0000000100462ae6 chromedriver + 662246\n6   chromedriver                        0x000000010049303d chromedriver + 860221\n7   chromedriver                        0x00000001004629c1 chromedriver + 661953\n8   chromedriver                        0x00000001004931ce chromedriver + 860622\n9   chromedriver                        0x00000001004ade76 chromedriver + 970358\n10  chromedriver                        0x0000000100492de3 chromedriver + 859619\n11  chromedriver                        0x0000000100460d7f chromedriver + 654719\n12  chromedriver                        0x00000001004620de chromedriver + 659678\n13  chromedriver                        0x00000001008322ad chromedriver + 4657837\n14  chromedriver                        0x0000000100837130 chromedriver + 4677936\n15  chromedriver                        0x000000010083ddef chromedriver + 4705775\n16  chromedriver                        0x000000010083805a chromedriver + 4681818\n17  chromedriver                        0x000000010080a92c chromedriver + 4495660\n18  chromedriver                        0x0000000100855838 chromedriver + 4802616\n19  chromedriver                        0x00000001008559b7 chromedriver + 4802999\n20  chromedriver                        0x000000010086699f chromedriver + 4872607\n21  libsystem_pthread.dylib             0x00007fff206aa8fc _pthread_start + 224\n22  libsystem_pthread.dylib             0x00007fff206a6443 thread_start + 15\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "def search_amazon_product(product_name):\n",
    "    service = Service('/Users/nafeesahussain/Desktop/FlipRobo_Internship/chromedriver_mac64/chromedriver')  \n",
    "    driver = webdriver.Chrome(service=service)\n",
    "    driver.get('https://www.amazon.in/')\n",
    "\n",
    "    try:\n",
    "        search_box = driver.find_element(By.ID, 'twotabsearchtextbox')\n",
    "        search_box.send_keys(product_name)\n",
    "        search_box.send_keys(Keys.RETURN)\n",
    "\n",
    "        products = []\n",
    "\n",
    "        product_elements = driver.find_elements(By.CSS_SELECTOR, 'div[data-asin]')\n",
    "        for product_element in product_elements:\n",
    "            product_title = product_element.find_element(By.CLASS_NAME, 'a-text-normal').text\n",
    "            product_price = product_element.find_element(By.CSS_SELECTOR, 'span.a-price span.a-offscreen').text\n",
    "            products.append((product_title, product_price))\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    return products\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    search_term = input(\"Enter the product to search: \")\n",
    "    products_list = search_amazon_product(search_term)\n",
    "\n",
    "    print(f\"Results for '{search_term}':\")\n",
    "    for index, product in enumerate(products_list, start=1):\n",
    "        title, price = product\n",
    "        print(f\"{index}. {title}\")\n",
    "        print(f\"   Price: {price}\")\n",
    "        print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5443b0a4",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cd74297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the product to search: bag\n",
      "Scraped data saved to 'bag_products.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "def scrape_amazon_products(search_term, num_pages=3):\n",
    "    service = Service('/Users/nafeesahussain/Desktop/FlipRobo_Internship/chromedriver_mac64/chromedriver')  \n",
    "    driver = webdriver.Chrome(service=service)\n",
    "    driver.get('https://www.amazon.in/')\n",
    "\n",
    "    try:\n",
    "        search_box = driver.find_element(By.ID, 'twotabsearchtextbox')\n",
    "        search_box.send_keys(search_term)\n",
    "        search_box.send_keys(Keys.RETURN)\n",
    "\n",
    "        products_data = []\n",
    "\n",
    "        for _ in range(num_pages):\n",
    "            product_elements = driver.find_elements(By.CSS_SELECTOR, 'div[data-asin]')\n",
    "            for product_element in product_elements:\n",
    "                product_data = {}\n",
    "\n",
    "                try:\n",
    "                    product_data['Brand Name'] = product_element.find_element(By.CLASS_NAME, 'a-size-base-plus').text\n",
    "                except:\n",
    "                    product_data['Brand Name'] = '-'\n",
    "\n",
    "                try:\n",
    "                    product_data['Name of the Product'] = product_element.find_element(By.CLASS_NAME, 'a-text-normal').text\n",
    "                except:\n",
    "                    product_data['Name of the Product'] = '-'\n",
    "\n",
    "                try:\n",
    "                    product_data['Price'] = product_element.find_element(By.CSS_SELECTOR, 'span.a-price span.a-offscreen').text\n",
    "                except:\n",
    "                    product_data['Price'] = '-'\n",
    "\n",
    "                try:\n",
    "                    product_data['Return/Exchange'] = product_element.find_element(By.CSS_SELECTOR, '.a-column.a-span3 span:nth-child(2)').text\n",
    "                except:\n",
    "                    product_data['Return/Exchange'] = '-'\n",
    "\n",
    "                try:\n",
    "                    product_data['Expected Delivery'] = product_element.find_element(By.CSS_SELECTOR, '.a-column.a-span3 span.a-text-bold').text\n",
    "                except:\n",
    "                    product_data['Expected Delivery'] = '-'\n",
    "\n",
    "                try:\n",
    "                    product_data['Availability'] = product_element.find_element(By.CSS_SELECTOR, '.a-column.a-span3 span.a-text-success').text\n",
    "                except:\n",
    "                    product_data['Availability'] = '-'\n",
    "\n",
    "                try:\n",
    "                    product_data['Product URL'] = product_element.find_element(By.CLASS_NAME, 'a-link-normal').get_attribute('href')\n",
    "                except:\n",
    "                    product_data['Product URL'] = '-'\n",
    "\n",
    "                products_data.append(product_data)\n",
    "\n",
    "            try:\n",
    "                next_button = driver.find_element(By.CLASS_NAME, 's-pagination-next')\n",
    "                next_button.click()\n",
    "            except:\n",
    "                break\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    return products_data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    search_term = input(\"Enter the product to search: \")\n",
    "    num_pages = 3\n",
    "    products_data = scrape_amazon_products(search_term, num_pages)\n",
    "\n",
    "    df = pd.DataFrame(products_data)\n",
    "\n",
    "    # Saving dataframe in CSV file\n",
    "    csv_filename = f\"{search_term}_products.csv\"\n",
    "    df.to_csv(csv_filename, index=False)\n",
    "\n",
    "    print(f\"Scraped data saved to '{csv_filename}'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a9134f",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cbdcab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /Users/nafeesahussain/opt/anaconda3/lib/python3.8/site-packages (4.10.0)\n",
      "Requirement already satisfied: requests in /Users/nafeesahussain/opt/anaconda3/lib/python3.8/site-packages (2.29.0)\n",
      "Requirement already satisfied: Pillow in /Users/nafeesahussain/opt/anaconda3/lib/python3.8/site-packages (9.4.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in /Users/nafeesahussain/opt/anaconda3/lib/python3.8/site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in /Users/nafeesahussain/opt/anaconda3/lib/python3.8/site-packages (from selenium) (0.21.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /Users/nafeesahussain/opt/anaconda3/lib/python3.8/site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /Users/nafeesahussain/opt/anaconda3/lib/python3.8/site-packages (from selenium) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/nafeesahussain/opt/anaconda3/lib/python3.8/site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nafeesahussain/opt/anaconda3/lib/python3.8/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /Users/nafeesahussain/opt/anaconda3/lib/python3.8/site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sortedcontainers in /Users/nafeesahussain/opt/anaconda3/lib/python3.8/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in /Users/nafeesahussain/opt/anaconda3/lib/python3.8/site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: outcome in /Users/nafeesahussain/opt/anaconda3/lib/python3.8/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sniffio in /Users/nafeesahussain/opt/anaconda3/lib/python3.8/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in /Users/nafeesahussain/opt/anaconda3/lib/python3.8/site-packages (from trio-websocket~=0.9->selenium) (1.1.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /Users/nafeesahussain/opt/anaconda3/lib/python3.8/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /Users/nafeesahussain/opt/anaconda3/lib/python3.8/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.13.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium requests Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a591a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping images for keyword: fruits\n",
      "Scraping images for keyword: cars\n",
      "Scraping images for keyword: Machine Learning\n",
      "Scraping images for keyword: Guitar\n",
      "Scraping images for keyword: Cakes\n",
      "Image scraping and download completed successfully.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "def scrape_images(keyword, num_images=10):\n",
    "    base_url = \"https://images.google.com\"\n",
    "    search_term = f\"/search?q={keyword.replace(' ', '+')}&tbm=isch\"\n",
    "    \n",
    "    driver = webdriver.Chrome()  \n",
    "    driver.get(base_url + search_term)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    image_urls = []\n",
    "    \n",
    "    try:\n",
    "        for _ in range(3):  # Scrolling down 3 times to load more images dynamically\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(2)\n",
    "            \n",
    "        images = driver.find_elements(By.XPATH, \"//img[contains(@class, 'rg_i')]\")\n",
    "        \n",
    "        for image in images[:num_images]:\n",
    "            image_url = image.get_attribute(\"src\")\n",
    "            if image_url and image_url.startswith(\"http\"):\n",
    "                image_urls.append(image_url)\n",
    "        \n",
    "    finally:\n",
    "        driver.quit()\n",
    "    \n",
    "    return image_urls\n",
    "\n",
    "def download_images(keyword, image_urls):\n",
    "    directory = f\"./{keyword}_images\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    for i, image_url in enumerate(image_urls):\n",
    "        response = requests.get(image_url)\n",
    "        image = Image.open(BytesIO(response.content))\n",
    "        image_path = os.path.join(directory, f\"{keyword}_{i+1}.jpg\")\n",
    "        image.save(image_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    keywords = ['fruits', 'cars', 'Machine Learning', 'Guitar', 'Cakes']\n",
    "    num_images_to_scrape = 10\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        print(f\"Scraping images for keyword: {keyword}\")\n",
    "        image_urls = scrape_images(keyword, num_images_to_scrape)\n",
    "        download_images(keyword, image_urls)\n",
    "    \n",
    "    print(\"Image scraping and download completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5290408f",
   "metadata": {},
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "425a10c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /Users/nafeesahussain/opt/anaconda3/lib/python3.8/site-packages (4.10.0)\n",
      "Requirement already satisfied: pandas in /Users/nafeesahussain/opt/anaconda3/lib/python3.8/site-packages (1.3.5)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in /Users/nafeesahussain/opt/anaconda3/lib/python3.8/site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in /Users/nafeesahussain/opt/anaconda3/lib/python3.8/site-packages (from selenium) (0.21.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /Users/nafeesahussain/opt/anaconda3/lib/python3.8/site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /Users/nafeesahussain/opt/anaconda3/lib/python3.8/site-packages (from selenium) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/nafeesahussain/opt/anaconda3/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/nafeesahussain/opt/anaconda3/lib/python3.8/site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/nafeesahussain/opt/anaconda3/lib/python3.8/site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/nafeesahussain/opt/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /Users/nafeesahussain/opt/anaconda3/lib/python3.8/site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sortedcontainers in /Users/nafeesahussain/opt/anaconda3/lib/python3.8/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in /Users/nafeesahussain/opt/anaconda3/lib/python3.8/site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: idna in /Users/nafeesahussain/opt/anaconda3/lib/python3.8/site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in /Users/nafeesahussain/opt/anaconda3/lib/python3.8/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sniffio in /Users/nafeesahussain/opt/anaconda3/lib/python3.8/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in /Users/nafeesahussain/opt/anaconda3/lib/python3.8/site-packages (from trio-websocket~=0.9->selenium) (1.1.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /Users/nafeesahussain/opt/anaconda3/lib/python3.8/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /Users/nafeesahussain/opt/anaconda3/lib/python3.8/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.13.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f92d6cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the smartphone you want to search for: oneplus nord\n"
     ]
    },
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\".//div[@class='_4rR01T']\"}\n  (Session info: chrome=115.0.5790.170); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n0   chromedriver                        0x0000000104e456b8 chromedriver + 4937400\n1   chromedriver                        0x0000000104e3cb73 chromedriver + 4901747\n2   chromedriver                        0x00000001049fa616 chromedriver + 435734\n3   chromedriver                        0x0000000104a3de0f chromedriver + 712207\n4   chromedriver                        0x0000000104a3e0a1 chromedriver + 712865\n5   chromedriver                        0x0000000104a31ae6 chromedriver + 662246\n6   chromedriver                        0x0000000104a6203d chromedriver + 860221\n7   chromedriver                        0x0000000104a319c1 chromedriver + 661953\n8   chromedriver                        0x0000000104a621ce chromedriver + 860622\n9   chromedriver                        0x0000000104a7ce76 chromedriver + 970358\n10  chromedriver                        0x0000000104a61de3 chromedriver + 859619\n11  chromedriver                        0x0000000104a2fd7f chromedriver + 654719\n12  chromedriver                        0x0000000104a310de chromedriver + 659678\n13  chromedriver                        0x0000000104e012ad chromedriver + 4657837\n14  chromedriver                        0x0000000104e06130 chromedriver + 4677936\n15  chromedriver                        0x0000000104e0cdef chromedriver + 4705775\n16  chromedriver                        0x0000000104e0705a chromedriver + 4681818\n17  chromedriver                        0x0000000104dd992c chromedriver + 4495660\n18  chromedriver                        0x0000000104e24838 chromedriver + 4802616\n19  chromedriver                        0x0000000104e249b7 chromedriver + 4802999\n20  chromedriver                        0x0000000104e3599f chromedriver + 4872607\n21  libsystem_pthread.dylib             0x00007fff206aa8fc _pthread_start + 224\n22  libsystem_pthread.dylib             0x00007fff206a6443 thread_start + 15\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 82\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     80\u001b[0m     keyword \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter the smartphone you want to search for: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 82\u001b[0m     details \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_smartphone_details\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyword\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(details)\n\u001b[1;32m     84\u001b[0m     df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkeyword\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_search_results.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[10], line 20\u001b[0m, in \u001b[0;36mscrape_smartphone_details\u001b[0;34m(keyword)\u001b[0m\n\u001b[1;32m     17\u001b[0m products \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_elements(By\u001b[38;5;241m.\u001b[39mXPATH, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m//div[@class=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_1AtVbE\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m product \u001b[38;5;129;01min\u001b[39;00m products:\n\u001b[0;32m---> 20\u001b[0m     brand_name \u001b[38;5;241m=\u001b[39m \u001b[43mproduct\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXPATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.//div[@class=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_4rR01T\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m     21\u001b[0m     product_name \u001b[38;5;241m=\u001b[39m product\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mXPATH, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.//a[@class=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIRpwTa\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m     22\u001b[0m     color \u001b[38;5;241m=\u001b[39m product\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mXPATH, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.//a[@class=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIRpwTa\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]/following-sibling::div\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/selenium/webdriver/remote/webelement.py:417\u001b[0m, in \u001b[0;36mWebElement.find_element\u001b[0;34m(self, by, value)\u001b[0m\n\u001b[1;32m    414\u001b[0m     by \u001b[38;5;241m=\u001b[39m By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR\n\u001b[1;32m    415\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 417\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIND_CHILD_ELEMENT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43musing\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/selenium/webdriver/remote/webelement.py:395\u001b[0m, in \u001b[0;36mWebElement._execute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    393\u001b[0m     params \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    394\u001b[0m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id\n\u001b[0;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py:346\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    344\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/selenium/webdriver/remote/errorhandler.py:245\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    243\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[0;32m--> 245\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[0;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\".//div[@class='_4rR01T']\"}\n  (Session info: chrome=115.0.5790.170); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n0   chromedriver                        0x0000000104e456b8 chromedriver + 4937400\n1   chromedriver                        0x0000000104e3cb73 chromedriver + 4901747\n2   chromedriver                        0x00000001049fa616 chromedriver + 435734\n3   chromedriver                        0x0000000104a3de0f chromedriver + 712207\n4   chromedriver                        0x0000000104a3e0a1 chromedriver + 712865\n5   chromedriver                        0x0000000104a31ae6 chromedriver + 662246\n6   chromedriver                        0x0000000104a6203d chromedriver + 860221\n7   chromedriver                        0x0000000104a319c1 chromedriver + 661953\n8   chromedriver                        0x0000000104a621ce chromedriver + 860622\n9   chromedriver                        0x0000000104a7ce76 chromedriver + 970358\n10  chromedriver                        0x0000000104a61de3 chromedriver + 859619\n11  chromedriver                        0x0000000104a2fd7f chromedriver + 654719\n12  chromedriver                        0x0000000104a310de chromedriver + 659678\n13  chromedriver                        0x0000000104e012ad chromedriver + 4657837\n14  chromedriver                        0x0000000104e06130 chromedriver + 4677936\n15  chromedriver                        0x0000000104e0cdef chromedriver + 4705775\n16  chromedriver                        0x0000000104e0705a chromedriver + 4681818\n17  chromedriver                        0x0000000104dd992c chromedriver + 4495660\n18  chromedriver                        0x0000000104e24838 chromedriver + 4802616\n19  chromedriver                        0x0000000104e249b7 chromedriver + 4802999\n20  chromedriver                        0x0000000104e3599f chromedriver + 4872607\n21  libsystem_pthread.dylib             0x00007fff206aa8fc _pthread_start + 224\n22  libsystem_pthread.dylib             0x00007fff206a6443 thread_start + 15\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "def scrape_smartphone_details(keyword):\n",
    "    base_url = \"https://www.flipkart.com\"\n",
    "    search_term = f\"/search?q={keyword.replace(' ', '%20')}\"\n",
    "    \n",
    "    driver = webdriver.Chrome()  \n",
    "    driver.get(base_url + search_term)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    details_list = []\n",
    "    \n",
    "    try:\n",
    "        products = driver.find_elements(By.XPATH, \"//div[@class='_1AtVbE']\")\n",
    "        \n",
    "        for product in products:\n",
    "            brand_name = product.find_element(By.XPATH, \".//div[@class='_4rR01T']\").text\n",
    "            product_name = product.find_element(By.XPATH, \".//a[@class='IRpwTa']\").text\n",
    "            color = product.find_element(By.XPATH, \".//a[@class='IRpwTa']/following-sibling::div\").text\n",
    "            price = product.find_element(By.XPATH, \".//div[@class='_30jeq3']\").text\n",
    "            \n",
    "            try:\n",
    "                ram = product.find_element(By.XPATH, \".//li[contains(text(), 'RAM')]\").text.split()[-1]\n",
    "            except:\n",
    "                ram = \"-\"\n",
    "            \n",
    "            try:\n",
    "                storage = product.find_element(By.XPATH, \".//li[contains(text(), 'ROM')]\").text.split()[-1]\n",
    "            except:\n",
    "                storage = \"-\"\n",
    "            \n",
    "            try:\n",
    "                primary_camera = product.find_element(By.XPATH, \".//li[contains(text(), 'Primary Camera')]\").text.split()[-1]\n",
    "            except:\n",
    "                primary_camera = \"-\"\n",
    "            \n",
    "            try:\n",
    "                secondary_camera = product.find_element(By.XPATH, \".//li[contains(text(), 'Secondary Camera')]\").text.split()[-1]\n",
    "            except:\n",
    "                secondary_camera = \"-\"\n",
    "            \n",
    "            try:\n",
    "                display_size = product.find_element(By.XPATH, \".//li[contains(text(), 'Display Size')]\").text.split()[-1]\n",
    "            except:\n",
    "                display_size = \"-\"\n",
    "            \n",
    "            try:\n",
    "                battery_capacity = product.find_element(By.XPATH, \".//li[contains(text(), 'Battery Capacity')]\").text.split()[-1]\n",
    "            except:\n",
    "                battery_capacity = \"-\"\n",
    "            \n",
    "            try:\n",
    "                product_url = product.find_element(By.XPATH, \".//a[@class='IRpwTa']\").get_attribute(\"href\")\n",
    "            except:\n",
    "                product_url = \"-\"\n",
    "            \n",
    "            details_list.append({\n",
    "                \"Brand Name\": brand_name,\n",
    "                \"Smartphone Name\": product_name,\n",
    "                \"Colour\": color,\n",
    "                \"RAM\": ram,\n",
    "                \"Storage(ROM)\": storage,\n",
    "                \"Primary Camera\": primary_camera,\n",
    "                \"Secondary Camera\": secondary_camera,\n",
    "                \"Display Size\": display_size,\n",
    "                \"Battery Capacity\": battery_capacity,\n",
    "                \"Price\": price,\n",
    "                \"Product URL\": product_url\n",
    "            })\n",
    "        \n",
    "    finally:\n",
    "        driver.quit()\n",
    "    \n",
    "    return details_list\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    keyword = input(\"Enter the smartphone you want to search for: \")\n",
    "    \n",
    "    details = scrape_smartphone_details(keyword)\n",
    "    df = pd.DataFrame(details)\n",
    "    df.to_csv(f\"{keyword}_search_results.csv\", index=False)\n",
    "    \n",
    "    print(\"Scraping and CSV creation completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077f8127",
   "metadata": {},
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3855aef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /Users/nafeesahussain/opt/anaconda3/lib/python3.8/site-packages (2.29.0)\r\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/nafeesahussain/opt/anaconda3/lib/python3.8/site-packages (4.12.2)\r\n",
      "Requirement already satisfied: geopy in /Users/nafeesahussain/opt/anaconda3/lib/python3.8/site-packages (2.3.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/nafeesahussain/opt/anaconda3/lib/python3.8/site-packages (from requests) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nafeesahussain/opt/anaconda3/lib/python3.8/site-packages (from requests) (3.4)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/nafeesahussain/opt/anaconda3/lib/python3.8/site-packages (from requests) (1.26.16)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nafeesahussain/opt/anaconda3/lib/python3.8/site-packages (from requests) (2023.7.22)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/nafeesahussain/opt/anaconda3/lib/python3.8/site-packages (from beautifulsoup4) (2.4)\r\n",
      "Requirement already satisfied: geographiclib<3,>=1.52 in /Users/nafeesahussain/opt/anaconda3/lib/python3.8/site-packages (from geopy) (2.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install requests beautifulsoup4 geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9aa08e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the name of the city: London\n",
      "Coordinates using geopy: Latitude: 51.4893335, Longitude: -0.14405508452768728\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find coordinates using geopy.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 38\u001b[0m coordinates \u001b[38;5;241m=\u001b[39m \u001b[43mget_geospatial_coordinates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcity_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m coordinates:\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCoordinates using Google Maps: Latitude: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcoordinates[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Longitude: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcoordinates[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[12], line 19\u001b[0m, in \u001b[0;36mget_geospatial_coordinates\u001b[0;34m(city)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m coordinates_div:\n\u001b[1;32m     18\u001b[0m     coordinates \u001b[38;5;241m=\u001b[39m coordinates_div[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 19\u001b[0m     latitude, longitude \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mfloat\u001b[39m, \u001b[43mcoordinates\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m@\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m latitude, longitude\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "def get_geospatial_coordinates(city):\n",
    "    base_url = \"https://www.google.com/maps/search/\"\n",
    "    search_query = f\"{city.replace(' ', '+')}\"\n",
    "    url = f\"{base_url}{search_query}\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        coordinates_div = soup.find(\"meta\", itemprop=\"image\")\n",
    "        \n",
    "        if coordinates_div:\n",
    "            coordinates = coordinates_div[\"content\"]\n",
    "            latitude, longitude = map(float, coordinates.split(\"@\")[1].split(\",\"))\n",
    "            return latitude, longitude\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    city_name = input(\"Enter the name of the city: \")\n",
    "    geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "    \n",
    "    location = geolocator.geocode(city_name)\n",
    "    if location:\n",
    "        print(f\"Coordinates using geopy: Latitude: {location.latitude}, Longitude: {location.longitude}\")\n",
    "    else:\n",
    "        print(\"Could not find coordinates using geopy.\")\n",
    "    \n",
    "    coordinates = get_geospatial_coordinates(city_name)\n",
    "    if coordinates:\n",
    "        print(f\"Coordinates using Google Maps: Latitude: {coordinates[0]}, Longitude: {coordinates[1]}\")\n",
    "    else:\n",
    "        print(\"Could not find coordinates using Google Maps.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d2e6da",
   "metadata": {},
   "source": [
    "### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a56141b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Laptop 1 ---\n",
      "Name: -\n",
      "Price: -\n",
      "Specifications: -\n",
      "Rating: -\n",
      "Image URL: Image not available\n",
      "\n",
      "\n",
      "--- Laptop 2 ---\n",
      "Name: -\n",
      "Price: -\n",
      "Specifications: -\n",
      "Rating: -\n",
      "Image URL: Image not available\n",
      "\n",
      "\n",
      "--- Laptop 3 ---\n",
      "Name: -\n",
      "Price: -\n",
      "Specifications: -\n",
      "Rating: -\n",
      "Image URL: Image not available\n",
      "\n",
      "\n",
      "--- Laptop 4 ---\n",
      "Name: -\n",
      "Price: -\n",
      "Specifications: -\n",
      "Rating: -\n",
      "Image URL: Image not available\n",
      "\n",
      "\n",
      "--- Laptop 5 ---\n",
      "Name: -\n",
      "Price: -\n",
      "Specifications: -\n",
      "Rating: -\n",
      "Image URL: Image not available\n",
      "\n",
      "\n",
      "--- Laptop 6 ---\n",
      "Name: -\n",
      "Price: -\n",
      "Specifications: -\n",
      "Rating: -\n",
      "Image URL: Image not available\n",
      "\n",
      "\n",
      "--- Laptop 7 ---\n",
      "Name: -\n",
      "Price: -\n",
      "Specifications: -\n",
      "Rating: -\n",
      "Image URL: Image not available\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrape_gaming_laptops():\n",
    "    url = \"https://www.digit.in/top-products/best-gaming-laptops-40.html\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        laptops_list = soup.find_all(\"div\", class_=\"TopNumbeHeading\")\n",
    "        \n",
    "        laptop_details = []\n",
    "        \n",
    "        for laptop in laptops_list:\n",
    "            name = laptop.find(\"div\", class_=\"TopNumbeHeading\")\n",
    "            price = laptop.find(\"td\", class_=\"smprice\")\n",
    "            specs = laptop.find(\"div\", class_=\"Specs-Wrap\")\n",
    "            rating = laptop.find(\"td\", class_=\"smrating\")\n",
    "            image_url = laptop.find(\"img\")[\"data-src\"] if laptop.find(\"img\") else None\n",
    "            \n",
    "            laptop_info = {\n",
    "                \"Name\": name.text.strip() if name else \"-\",\n",
    "                \"Price\": price.text.strip().replace(\"Price : \", \"\") if price else \"-\",\n",
    "                \"Specifications\": specs.text.strip() if specs else \"-\",\n",
    "                \"Rating\": rating.text.strip().replace(\"Overall Rating : \", \"\") if rating else \"-\",\n",
    "                \"Image URL\": image_url if image_url else \"Image not available\"\n",
    "            }\n",
    "            \n",
    "            laptop_details.append(laptop_info)\n",
    "        \n",
    "        return laptop_details\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return []\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    gaming_laptops = scrape_gaming_laptops()\n",
    "    \n",
    "    if gaming_laptops:\n",
    "        for idx, laptop in enumerate(gaming_laptops, start=1):\n",
    "            print(f\"--- Laptop {idx} ---\")\n",
    "            print(\"Name:\", laptop[\"Name\"])\n",
    "            print(\"Price:\", laptop[\"Price\"])\n",
    "            print(\"Specifications:\", laptop[\"Specifications\"])\n",
    "            print(\"Rating:\", laptop[\"Rating\"])\n",
    "            print(\"Image URL:\", laptop[\"Image URL\"])\n",
    "            print(\"\\n\")\n",
    "    else:\n",
    "        print(\"No data found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5031af1a",
   "metadata": {},
   "source": [
    "### Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28e2ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install requests beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4033cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "def scrape_forbes_billionaires(url):\n",
    "    \n",
    "    service = Service('/Users/nafeesahussain/Desktop/FlipRobo_Internship/chromedriver_mac64/chromedriver')  \n",
    "    driver = webdriver.Chrome(service=service)\n",
    "    driver.get(url)\n",
    "\n",
    "    billionaires = []\n",
    "\n",
    "    try:\n",
    "        table_rows = driver.find_elements(By.XPATH, \"//table[@class='data']/tbody/tr\")\n",
    "        \n",
    "        for row in table_rows:\n",
    "            cols = row.find_elements(By.TAG_NAME, \"td\")\n",
    "            if len(cols) >= 7:\n",
    "                rank = cols[0].text.strip()\n",
    "                name = cols[1].text.strip()\n",
    "                net_worth = cols[2].text.strip()\n",
    "                age = cols[3].text.strip()\n",
    "                citizenship = cols[4].text.strip()\n",
    "                source = cols[5].text.strip()\n",
    "                industry = cols[6].text.strip()\n",
    "\n",
    "                billionaire = {\n",
    "                    \"Rank\": rank,\n",
    "                    \"Name\": name,\n",
    "                    \"Net worth\": net_worth,\n",
    "                    \"Age\": age,\n",
    "                    \"Citizenship\": citizenship,\n",
    "                    \"Source\": source,\n",
    "                    \"Industry\": industry\n",
    "                }\n",
    "\n",
    "                billionaires.append(billionaire)\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    return billionaires\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    url = \"https://www.forbes.com/billionaires/\"  \n",
    "    billionaires_list = scrape_forbes_billionaires(url)\n",
    "\n",
    "    for billionaire in billionaires_list:\n",
    "        print(\"Rank:\", billionaire[\"Rank\"])\n",
    "        print(\"Name:\", billionaire[\"Name\"])\n",
    "        print(\"Net Worth:\", billionaire[\"Net worth\"])\n",
    "        print(\"Age:\", billionaire[\"Age\"])\n",
    "        print(\"Citizenship:\", billionaire[\"Citizenship\"])\n",
    "        print(\"Source:\", billionaire[\"Source\"])\n",
    "        print(\"Industry:\", billionaire[\"Industry\"])\n",
    "        print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3315c745",
   "metadata": {},
   "source": [
    "### Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfc7c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install google-api-python-client google-auth-httplib2 google-auth-oauthlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ecd5f797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment: This guy&#39;s voice sounds like the speech device that Stephen Hawking would use to communicate.\n",
      "Upvotes: 1\n",
      "Timestamp: 2023-01-12T19:32:23Z\n",
      "==================================================\n",
      "Comment: hello, everyone can any body tell me about software, where i can develop 5 axis ABB robot water jet cutting program by using 3D CAD models.\n",
      "Upvotes: 0\n",
      "Timestamp: 2022-01-15T03:33:07Z\n",
      "==================================================\n",
      "Comment: OMG sweden the most developed country\n",
      "Upvotes: 0\n",
      "Timestamp: 2021-09-29T15:49:39Z\n",
      "==================================================\n",
      "Comment: Would i be able to get to learn more about this through like an Intership?\n",
      "Upvotes: 0\n",
      "Timestamp: 2021-08-16T17:01:36Z\n",
      "==================================================\n",
      "Comment: Hanzhen harmonic drive gear ,  over 30 years experience in  robot gear box\n",
      "Upvotes: 0\n",
      "Timestamp: 2021-08-09T03:03:08Z\n",
      "==================================================\n",
      "Comment: fuck\n",
      "Upvotes: 0\n",
      "Timestamp: 2021-06-30T09:41:47Z\n",
      "==================================================\n",
      "Comment: Great \n",
      "Upvotes: 1\n",
      "Timestamp: 2021-06-20T12:09:13Z\n",
      "==================================================\n",
      "Comment: What happens to the workers these robots replace?\n",
      "Upvotes: 0\n",
      "Timestamp: 2021-02-14T07:03:40Z\n",
      "==================================================\n",
      "Comment: So after 40 odd years of development the key point is we changed the color!\n",
      "Upvotes: 0\n",
      "Timestamp: 2020-12-11T13:27:36Z\n",
      "==================================================\n",
      "<br>ABB RobotStudio Robot Simulation and Programming with English-<a href=\"https://www.udemy.com/course/abb-robotstudio-training/?couponCode=69CAFD770D5B4AF13A11\">https://www.udemy.com/course/abb-robotstudio-training/?couponCode=69CAFD770D5B4AF13A11</a>\n",
      "Upvotes: 0\n",
      "Timestamp: 2020-12-08T12:00:41Z\n",
      "==================================================\n",
      "Comment: Hi..We ( Industrial Automation Consultants ) are looking for technical collaborations with companies engaged in Solar , Electrical Engineering or other related multi disciplinary. We have around 40 years of expertise. Pls contact Mr.Rathinasamy 9840254674..\n",
      "Upvotes: 0\n",
      "Timestamp: 2020-10-29T02:26:35Z\n",
      "==================================================\n",
      "Comment: Welding robotics programmer work\n",
      "Upvotes: 0\n",
      "Timestamp: 2020-08-02T18:55:38Z\n",
      "==================================================\n",
      "Comment: I love ABB robotics <br>I&#39;m ABB robotics programmer and opretor working uae <br>I need course training certificate please how getting me I have only experience\n",
      "Upvotes: 0\n",
      "Timestamp: 2020-08-02T18:54:56Z\n",
      "==================================================\n",
      "Comment: Well what can the robots do? not important! But we now know that we can order any color ... ... function is nothing, design is everything.\n",
      "Upvotes: 0\n",
      "Timestamp: 2020-06-11T16:10:45Z\n",
      "==================================================\n",
      "Comment: I program ABB and they are quite amazing.\n",
      "Upvotes: 6\n",
      "Timestamp: 2020-06-05T12:22:58Z\n",
      "==================================================\n",
      "Comment: At my factory..this robot keep sleeping..anyone know how to do?\n",
      "Upvotes: 0\n",
      "Timestamp: 2020-04-22T04:43:04Z\n",
      "==================================================\n",
      "Comment: These guys came to my school lmao \n",
      "Upvotes: 0\n",
      "Timestamp: 2020-03-13T23:10:42Z\n",
      "==================================================\n",
      "Comment: \n",
      "Upvotes: 0\n",
      "Timestamp: 2020-03-04T15:30:24Z\n",
      "==================================================\n",
      "Comment:   - KUKA  .\n",
      "Upvotes: 0\n",
      "Timestamp: 2019-11-26T19:21:22Z\n",
      "==================================================\n",
      "Comment: Great!!!\n",
      "Upvotes: 0\n",
      "Timestamp: 2019-08-14T09:01:44Z\n",
      "==================================================\n",
      "Comment: For more project <br><a href=\"https://www.youtube.com/watch?v=FfDH5xOEp_s\">https://www.youtube.com/watch?v=FfDH5xOEp_s</a>\n",
      "Upvotes: 0\n",
      "Timestamp: 2019-07-29T02:00:23Z\n",
      "==================================================\n",
      "Comment: Vinfast is using ABB Robots for manufacturing automobile. Thank you for supporting Vietnam.\n",
      "Upvotes: 2\n",
      "Timestamp: 2019-06-19T08:13:49Z\n",
      "==================================================\n",
      "Comment: Construction robota... Ist das next\n",
      "Upvotes: 0\n",
      "Timestamp: 2019-05-25T23:40:35Z\n",
      "==================================================\n",
      "Comment: You know this shit gets me wet.\n",
      "Upvotes: 0\n",
      "Timestamp: 2019-05-19T00:31:46Z\n",
      "==================================================\n",
      "Comment: ABB should take a look at the 22-headed talent team at Unibap in Sweden. They launch ideas that will make big difference in the smart factories and world of robotics: <a href=\"http://www.unibap.com/\">www.unibap.com</a>\n",
      "Upvotes: 0\n",
      "Timestamp: 2018-11-11T10:13:17Z\n",
      "==================================================\n",
      "Comment: One of my favourite mnc..\n",
      "Upvotes: 5\n",
      "Timestamp: 2018-10-20T06:44:59Z\n",
      "==================================================\n",
      "Comment: Want robot\n",
      "Upvotes: 0\n",
      "Timestamp: 2018-08-29T11:34:16Z\n",
      "==================================================\n",
      "Comment: Thank you\n",
      "Upvotes: 0\n",
      "Timestamp: 2018-08-29T11:31:54Z\n",
      "==================================================\n",
      "Comment: Plc\n",
      "Upvotes: 0\n",
      "Timestamp: 2018-07-31T01:40:51Z\n",
      "==================================================\n",
      "Comment: Embedded software\n",
      "Upvotes: 0\n",
      "Timestamp: 2018-07-31T01:40:14Z\n",
      "==================================================\n",
      "Comment: Abb Ltd calling\n",
      "Upvotes: 1\n",
      "Timestamp: 2018-07-25T07:27:57Z\n",
      "==================================================\n",
      "Comment: How would i contact you\n",
      "Upvotes: 0\n",
      "Timestamp: 2018-06-02T13:58:39Z\n",
      "==================================================\n",
      "Comment: sir <br>Nice video\n",
      "Upvotes: 0\n",
      "Timestamp: 2018-06-02T13:58:17Z\n",
      "==================================================\n",
      "Comment: Hide your face stupid man. The robot are most important.\n",
      "Upvotes: 1\n",
      "Timestamp: 2018-04-23T19:16:54Z\n",
      "==================================================\n",
      "Comment: Cant robots work in the dark?\n",
      "Upvotes: 0\n",
      "Timestamp: 2018-02-12T18:45:47Z\n",
      "==================================================\n",
      "Comment: job  me plz\n",
      "Upvotes: 0\n",
      "Timestamp: 2017-12-22T18:25:57Z\n",
      "==================================================\n",
      "Comment: thanks\n",
      "Upvotes: 0\n",
      "Timestamp: 2017-12-04T22:16:49Z\n",
      "==================================================\n",
      "Comment: ABB make robots.. anyone else rubish\n",
      "Upvotes: 2\n",
      "Timestamp: 2017-09-12T05:41:17Z\n",
      "==================================================\n",
      "Comment: Very good\n",
      "Upvotes: 0\n",
      "Timestamp: 2017-09-07T13:27:05Z\n",
      "==================================================\n",
      "Comment: Kudos on the innovation that has landed you on the RBR50 list.  Keep shaping the future.\n",
      "Upvotes: 2\n",
      "Timestamp: 2017-05-02T04:02:52Z\n",
      "==================================================\n",
      "Comment: <a href=\"http://www.youtube.com/watch?v=C5R-FSRBUbE&amp;t=1m24s\">1:24</a>, which side is the robot?\n",
      "Upvotes: 5\n",
      "Timestamp: 2017-04-10T05:13:31Z\n",
      "==================================================\n",
      "Comment: more of the same. what&#39;s new?\n",
      "Upvotes: 1\n",
      "Timestamp: 2017-03-14T21:15:37Z\n",
      "==================================================\n",
      "Comment: i wanted to know about the technology and <a href=\"http://www.youtube.com/watch?v=C5R-FSRBUbE&amp;t=3m44s\">3:44</a> of someone talking about the new paint job\n",
      "Upvotes: 4\n",
      "Timestamp: 2017-02-07T08:48:13Z\n",
      "==================================================\n",
      "Comment: Our SOFTROBOT is esay to buy &amp; work ability is connect million of equipment of millions of work. thank you support ROBOT for future.\n",
      "Upvotes: 0\n",
      "Timestamp: 2016-11-27T04:28:33Z\n",
      "==================================================\n",
      "Comment: Use SOFT ROBOT..\n",
      "Upvotes: 0\n",
      "Timestamp: 2016-11-26T12:35:27Z\n",
      "==================================================\n",
      "Comment: Nice\n",
      "Upvotes: 0\n",
      "Timestamp: 2016-11-13T04:21:26Z\n",
      "==================================================\n",
      "Comment: Thanks. B R\n",
      "Upvotes: 0\n",
      "Timestamp: 2016-09-22T02:43:55Z\n",
      "==================================================\n",
      "Comment: Abb and Kuka Robotic Engineers How About Talking Relationship Robotics Bear A Labour Head Face into All Industrial Robots.Unfit Mobile -Radio waves Control Devices Onto All Abb And All World Industrial Robotics.I think Electro Magnetic Self Generating Electrical Motors into All Abb And Kuka Kind Robots would Bear Independence into Our Robots.Bearing 360%Air Vacuum Magnetic Ball Wheels Underneath All Robots will Bear Them Mobuilty Around All Industrial Areas Global.I want to Become a Mechanic Working in Building Robotic Machines in Order to Bear My Own Machine Ideas into Our World.Need work with Your Abb Kuka and World Robotic Companies.<br><br><br><br>\n",
      "Upvotes: 0\n",
      "Timestamp: 2016-06-14T12:28:12Z\n",
      "==================================================\n",
      "Comment: P Uno1 1st Bearer. Engineer to Suggest Bearering Engineering Mobile 2Way Camera to Camera Computerised And Orbital Satellites Operational Shortwaves Frequencies Morse Codeing World and Radios would be Good .Bearing into All Abb Kuka and All Universal Planetary Environmental Industrial Robots Satellites Operational Radio Waves Voice RELATIONSHIPS.1st Talking Abb Kuka Industrial Robots.Bringing Engineers and Robots Closer Together Globally.Live Orbital Satellites Op Global C.C.T.V. Environmental Industrial Robotic Management Services Needs to be Established Globally.Also Surggest that We Engineer Magnetic Perpetual Electrical Self Generating Mechanical Industrial Robots Into Our World.Forward with Our Robotic Mechanical Evolutions .Reciveing Very Special Orbital Satellites. Operational Shortwaves Frequencies Morse Coding Reverse Mechanical Sounding Patterning Electro Magnetic Radiocyclewaves Transmissions Kindly in My Shortwaves Frequencies World and Radios.Want All In NATO Militaries and none Militaries plus All Universal Planetary Defence Anti Nuclear Diffusions Disarming Engineers to Use These Wonderful Radiocyclewaves Transmissions for Universal Planetary Programmed Radio CNC Automated Robotic Mechanically Assisted Nuclear none Nuclear Diffusions Disarmament Engineering Labours Kind.\n",
      "Upvotes: 0\n",
      "Timestamp: 2016-06-14T12:14:25Z\n",
      "==================================================\n",
      "Comment: with anykind of robot if you put an error on an axes you need to repair the axes, with an abb robot you just need to reset and go back to the last good point know, abb for life ;)\n",
      "Upvotes: 8\n",
      "Timestamp: 2016-01-10T15:40:38Z\n",
      "==================================================\n",
      "Comment: building Up\n",
      "Upvotes: 0\n",
      "Timestamp: 2015-12-28T18:53:18Z\n",
      "==================================================\n",
      "Comment: my college lab owned one of this and professor asked me to take charge of it.... excited....i don&#39;t even know robotstudio\n",
      "Upvotes: 1\n",
      "Timestamp: 2015-10-26T10:51:48Z\n",
      "==================================================\n",
      "Comment: como hago para recibir apoyo de su compaia con quien me contacto\n",
      "Upvotes: 0\n",
      "Timestamp: 2015-10-24T16:17:34Z\n",
      "==================================================\n",
      "Comment: amo meu trabalho\n",
      "Upvotes: 0\n",
      "Timestamp: 2015-08-25T13:10:55Z\n",
      "==================================================\n",
      "Comment: Amazing machines\n",
      "Upvotes: 2\n",
      "Timestamp: 2015-03-24T07:37:40Z\n",
      "==================================================\n",
      "Comment: Amazing machines\n",
      "Upvotes: 1\n",
      "Timestamp: 2015-03-24T07:37:37Z\n",
      "==================================================\n",
      "Comment: nice robots!\n",
      "Upvotes: 0\n",
      "Timestamp: 2015-03-22T17:17:17Z\n",
      "==================================================\n",
      "Comment: In just info abb technologi yang akan kita kembang di aceh, its the produks knowlarged end subtitle emergency power and tecnologi benefit income quality control management suite otomotif in capital rasio city line improve management.\n",
      "Upvotes: 0\n",
      "Timestamp: 2015-03-20T09:38:54Z\n",
      "==================================================\n",
      "Comment: Welcome to the new era of accessorizing robots! LOL\n",
      "Upvotes: 0\n",
      "Timestamp: 2014-09-24T22:19:15Z\n",
      "==================================================\n",
      "Comment: Now they just need to invent Glados and the testing can begin\n",
      "Upvotes: 9\n",
      "Timestamp: 2014-06-05T16:48:23Z\n",
      "==================================================\n",
      "Comment: Super! :) (y)\n",
      "Upvotes: 0\n",
      "Timestamp: 2014-05-14T06:23:59Z\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import google.oauth2.credentials\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "API_KEY = \"AIzaSyAWoxqZE5KAiff_dZewy8rXpFIK80rUNxQ\"\n",
    "VIDEO_ID = \"C5R-FSRBUbE\"\n",
    "\n",
    "youtube = build(\"youtube\", \"v3\", developerKey=API_KEY)\n",
    "\n",
    "def get_video_comments(video_id):\n",
    "    comments = []\n",
    "    nextPageToken = None\n",
    "\n",
    "    while True:\n",
    "        response = youtube.commentThreads().list(\n",
    "            part=\"snippet\",\n",
    "            videoId=video_id,\n",
    "            maxResults=100,\n",
    "            pageToken=nextPageToken\n",
    "        ).execute()\n",
    "\n",
    "        for item in response[\"items\"]:\n",
    "            comment = item[\"snippet\"][\"topLevelComment\"][\"snippet\"]\n",
    "            comments.append({\n",
    "                \"comment\": comment[\"textDisplay\"],\n",
    "                \"upvotes\": comment[\"likeCount\"],\n",
    "                \"timestamp\": comment[\"publishedAt\"]\n",
    "            })\n",
    "\n",
    "        nextPageToken = response.get(\"nextPageToken\")\n",
    "\n",
    "        if not nextPageToken or len(comments) >= 500:\n",
    "            break\n",
    "\n",
    "    return comments\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    video_comments = get_video_comments(VIDEO_ID)\n",
    "    \n",
    "    for comment in video_comments:\n",
    "        print(\"Comment:\", comment[\"comment\"])\n",
    "        print(\"Upvotes:\", comment[\"upvotes\"])\n",
    "        print(\"Timestamp:\", comment[\"timestamp\"])\n",
    "        print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492a9e8d",
   "metadata": {},
   "source": [
    "### Question 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a86044b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e15deb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "def scrape_hostels(url):\n",
    "    service = Service('/Users/nafeesahussain/Desktop/FlipRobo_Internship/chromedriver_mac64/chromedriver')  \n",
    "    driver = webdriver.Chrome(service=service)\n",
    "    driver.get(url)\n",
    "\n",
    "    hostels = []\n",
    "\n",
    "    try:\n",
    "        hostel_cards = driver.find_elements(By.CLASS_NAME, 'fabresult')\n",
    "        for card in hostel_cards:\n",
    "            hostel = {}\n",
    "\n",
    "            hostel['name'] = card.find_element(By.CLASS_NAME, 'title').text.strip()\n",
    "            hostel['distance'] = card.find_element(By.CLASS_NAME, 'distance').text.strip()\n",
    "            hostel['ratings'] = card.find_element(By.CLASS_NAME, 'score').text.strip()\n",
    "            hostel['total_reviews'] = card.find_element(By.CLASS_NAME, 'reviews').text.strip()\n",
    "            hostel['overall_reviews'] = card.find_element(By.CLASS_NAME, 'keyword').text.strip()\n",
    "            hostel['privates_price'] = card.find_element(By.CLASS_NAME, 'price').text.strip()\n",
    "            hostel['facilities'] = ', '.join([item.text.strip() for item in card.find_elements(By.CLASS_NAME, 'label')])\n",
    "            hostel['description'] = card.find_element(By.CLASS_NAME, 'description').text.strip()\n",
    "\n",
    "            hostels.append(hostel)\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    return hostels\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    url = \"https://www.hostelworld.com/search?search_keywords=London,%20England&country=England&city=London&type=city&id=3&from=2023-08-01&to=2023-08-15&guests=1&page=1\"\n",
    "    hostels_list = scrape_hostels(url)\n",
    "\n",
    "    for hostel in hostels_list:\n",
    "        print(\"Name:\", hostel[\"name\"])\n",
    "        print(\"Distance from City Centre:\", hostel[\"distance\"])\n",
    "        print(\"Ratings:\", hostel[\"ratings\"])\n",
    "        print(\"Total Reviews:\", hostel[\"total_reviews\"])\n",
    "        print(\"Overall Reviews:\", hostel[\"overall_reviews\"])\n",
    "        print(\"Privates Price:\", hostel[\"privates_price\"])\n",
    "        print(\"Facilities:\", hostel[\"facilities\"])\n",
    "        print(\"Description:\", hostel[\"description\"])\n",
    "        print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec18b6e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
